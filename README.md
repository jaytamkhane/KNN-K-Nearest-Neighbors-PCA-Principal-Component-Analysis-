# KNN and PCA: Concepts, Theories & Practical Implementations

This repository contains a comprehensive assignment on **K-Nearest Neighbors (KNN)** and **Principal Component Analysis (PCA)**. It includes theoretical explanations, coding exercises, and experiments using various configurations and datasets.

## ğŸ“Œ Topics Covered

### ğŸ” Theoretical Questions
- What is KNN and how it works
- Difference between KNN Classification and Regression
- Distance metrics in KNN
- Curse of Dimensionality

### ğŸ§  Practical Assignments
- Train KNN Classifier on Iris Dataset
- Train KNN Regressor on synthetic data
- Experiment with distance metrics (Euclidean vs Manhattan)
- Visualize decision boundaries for various K
- Feature scaling impact on KNN performance

## ğŸ’» Technologies Used
- Python
- Jupyter Notebook
- Scikit-learn
- Matplotlib / Seaborn
- NumPy / Pandas

## ğŸ—‚ï¸ Folder Structure

[KKN_&_PCA.ipynb](https://github.com/jaytamkhane/KNN-K-Nearest-Neighbors-PCA-Principal-Component-Analysis-/blob/main/KNN_%26_PCA.ipynb) # Main jupyter file


## ğŸ“Š Learning Objectives
- Understand the theory behind KNN and PCA.
- Apply machine learning techniques using Scikit-learn.
- Use PCA for dimensionality reduction and analysis.
- Evaluate model performance using different metrics.

## âœï¸ Author
**Jaykumar Tamkhane** 

---
